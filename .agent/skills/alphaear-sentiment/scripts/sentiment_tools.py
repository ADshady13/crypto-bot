import os
from typing import Dict, List, Union, Optional
import json
from loguru import logger
# IMPORTS REMOVED: agno.agent, get_model
# Internal LLM logic has been removed to delegate analysis to the calling Agent.
from .database_manager import DatabaseManager

# ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–é»˜è®¤æƒ…ç»ªåˆ†æžæ¨¡å¼
DEFAULT_SENTIMENT_MODE = os.getenv("SENTIMENT_MODE", "auto")  # auto, bert, llm

class SentimentTools:
    """
    æƒ…ç»ªåˆ†æžå·¥å…· - æ”¯æŒ LLM å’Œ BERT ä¸¤ç§æ¨¡å¼
    
    æ¨¡å¼è¯´æ˜Ž:
    - "auto": è‡ªåŠ¨é€‰æ‹©ï¼Œä¼˜å…ˆä½¿ç”¨ BERTï¼ˆé€Ÿåº¦å¿«ï¼‰ï¼Œä¸å¯ç”¨æ—¶å›žé€€åˆ° LLM
    - "bert": å¼ºåˆ¶ä½¿ç”¨ BERT æ¨¡åž‹ï¼ˆéœ€è¦ transformers åº“ï¼‰
    - "llm": å¼ºåˆ¶ä½¿ç”¨ LLMï¼ˆæ›´å‡†ç¡®ä½†è¾ƒæ…¢ï¼‰
    
    å¯é€šè¿‡çŽ¯å¢ƒå˜é‡ SENTIMENT_MODE è®¾ç½®é»˜è®¤æ¨¡å¼ã€‚
    """
    
    def __init__(self, db: DatabaseManager, mode: Optional[str] = None):
        """
        åˆå§‹åŒ–æƒ…ç»ªåˆ†æžå·¥å…·ã€‚
        
        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨å®žä¾‹
            mode: åˆ†æžæ¨¡å¼ï¼Œå¯é€‰ "auto", "bert", "llm"ã€‚None åˆ™ä½¿ç”¨çŽ¯å¢ƒå˜é‡é»˜è®¤å€¼ã€‚
            model_provider: LLM æä¾›å•†ï¼Œå¦‚ "openai", "ust", "deepseek"
            model_id: æ¨¡åž‹æ ‡è¯†ç¬¦
        """
        self.db = db
        self.mode = mode or DEFAULT_SENTIMENT_MODE
        self.bert_pipeline = None
        
        # LLM initialization removed. Agent should perform analysis if needed.

        # Initialize BERT if needed
        if self.mode in ["bert", "auto"]:
            try:
                from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
                from transformers.utils import logging as transformers_logging
                transformers_logging.set_verbosity_error() # å‡å°‘å†—ä½™æ—¥å¿—
                
                bert_model = os.getenv("BERT_SENTIMENT_MODEL", "uer/roberta-base-finetuned-chinanews-chinese")
                
                # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜
                try:
                    tokenizer = AutoTokenizer.from_pretrained(bert_model, local_files_only=True)
                    model = AutoModelForSequenceClassification.from_pretrained(bert_model, local_files_only=True)
                    
                    self.bert_pipeline = pipeline(
                        "sentiment-analysis", 
                        model=model,
                        tokenizer=tokenizer,
                        device=-1
                    )
                    logger.info(f"âœ… BERT pipeline loaded from local cache: {bert_model}")
                except (OSError, ValueError, ImportError):
                    # æœ¬åœ°æ²¡æœ‰ï¼Œåˆ™ä»Žç½‘ç»œä¸‹è½½
                    logger.info(f"ðŸ“¡ Downloading BERT model: {bert_model}...")
                    tokenizer = AutoTokenizer.from_pretrained(bert_model)
                    model = AutoModelForSequenceClassification.from_pretrained(bert_model)
                    
                    self.bert_pipeline = pipeline(
                        "sentiment-analysis", 
                        model=model,
                        tokenizer=tokenizer,
                        device=-1
                    )
                    logger.info(f"âœ… BERT Sentiment pipeline ({bert_model}) initialized.")
            except ImportError:
                logger.warning("Transformers library not installed. BERT sentiment analysis disabled.")
            except Exception as e:
                if self.mode == "bert":
                    logger.error(f"BERT mode requested but failed: {e}")
                else:
                    logger.warning(f"BERT unavailable, using LLM only. Error: {e}")
                self.bert_pipeline = None


    def analyze_sentiment(self, text: str) -> Dict[str, Union[float, str]]:
        """
        åˆ†æžæ–‡æœ¬çš„æƒ…ç»ªæžæ€§ã€‚ä»…æ”¯æŒ BERT æ¨¡å¼ã€‚
        å¦‚éœ€ LLM åˆ†æžï¼Œè¯· Agent æŒ‰ç…§ SKILL.md ä¸­çš„ Prompt è‡ªè¡Œæ‰§è¡Œã€‚
        
        Args:
            text: éœ€è¦åˆ†æžçš„æ–‡æœ¬å†…å®¹ã€‚
        
        Returns:
            BERT åˆ†æžç»“æžœï¼Œæˆ–é”™è¯¯ä¿¡æ¯ã€‚
        """
        if self.bert_pipeline:
            results = self.analyze_sentiment_bert([text])
            return results[0] if results else {"score": 0.0, "label": "error"}
        else:
            return {
                "score": 0.0, 
                "label": "error", 
                "reason": "BERT pipeline not initialized. For LLM analysis, please manually execute the prompt in SKILL.md."
            }

    def update_single_news_sentiment(self, news_id: Union[str, int], score: float, reason: str = "") -> bool:
        """
        å…è®¸ Agent å°†æ‰‹åŠ¨åˆ†æžçš„ç»“æžœä¿å­˜åˆ°æ•°æ®åº“ã€‚
        
        Args:
            news_id: æ–°é—» ID
            score: -1.0 åˆ° 1.0
            reason: åˆ†æžç†ç”±
            
        Returns:
            Success bool
        """
        try:
            cursor = self.db.conn.cursor()
            cursor.execute("""
                UPDATE daily_news 
                SET sentiment_score = ?, meta_data = json_set(COALESCE(meta_data, '{}'), '$.sentiment_reason', ?)
                WHERE id = ?
            """, (score, reason, news_id))
            self.db.conn.commit()
            return True
        except Exception as e:
            logger.error(f"Failed to update sentiment for {news_id}: {e}")
            return False

    def analyze_sentiment_bert(self, texts: List[str]) -> List[Dict]:
        """
        ä½¿ç”¨ BERT è¿›è¡Œæ‰¹é‡é«˜é€Ÿæƒ…ç»ªåˆ†æžã€‚
        
        Args:
            texts: éœ€è¦åˆ†æžçš„æ–‡æœ¬åˆ—è¡¨ã€‚
        
        Returns:
            ä¸Žè¾“å…¥åˆ—è¡¨ç­‰é•¿çš„åˆ†æžç»“æžœåˆ—è¡¨ã€‚
        """
        if not self.bert_pipeline:
            return [{"score": 0.0, "label": "error", "reason": "BERT not available"}] * len(texts)
        
        try:
            results = self.bert_pipeline(texts, truncation=True, max_length=512)
            processed = []
            for r in results:
                label = r['label'].lower()
                score = r['score']
                
                # æ ‡å‡†åŒ–ä¸åŒæ¨¡åž‹çš„æ ‡ç­¾æ ¼å¼
                if 'negative' in label or 'neg' in label:
                    score = -score
                elif 'neutral' in label or 'neu' in label:
                    score = 0.0
                
                processed.append({
                    "score": float(round(score, 3)),
                    "label": "positive" if score > 0.1 else ("negative" if score < -0.1 else "neutral"),
                    "reason": "BERT automated analysis"
                })
            return processed
        except Exception as e:
            logger.error(f"BERT analysis failed: {e}")
            return [{"score": 0.0, "label": "error", "reason": str(e)}] * len(texts)

    def batch_update_news_sentiment(self, source: Optional[str] = None, limit: int = 50, use_bert: Optional[bool] = None):
        """
        æ‰¹é‡æ›´æ–°æ•°æ®åº“ä¸­æ–°é—»çš„æƒ…ç»ªåˆ†æ•°ã€‚
        
        Args:
            source: ç­›é€‰ç‰¹å®šæ–°é—»æºï¼Œå¦‚ "wallstreetcn"ã€‚None åˆ™å¤„ç†æ‰€æœ‰æ¥æºã€‚
            limit: æœ€å¤šå¤„ç†çš„æ–°é—»æ•°é‡ã€‚
            use_bert: æ˜¯å¦ä½¿ç”¨ BERTã€‚None åˆ™æ ¹æ®åˆå§‹åŒ–æ¨¡å¼è‡ªåŠ¨å†³å®šã€‚
        
        Returns:
            æˆåŠŸæ›´æ–°çš„æ–°é—»æ•°é‡ã€‚
        """
        news_items = self.db.get_daily_news(source=source, limit=limit)
        to_analyze = [item for item in news_items if not item.get('sentiment_score')]
        
        if not to_analyze:
            return 0

        updated_count = 0
        cursor = self.db.conn.cursor()

        # å†³å®šä½¿ç”¨å“ªç§æ–¹æ³•
        if self.bert_pipeline:
            logger.info(f"ðŸš€ Using BERT for batch analysis of {len(to_analyze)} items...")
            titles = [item['title'] for item in to_analyze]
            results = self.analyze_sentiment_bert(titles)
            
            for item, analysis in zip(to_analyze, results):
                cursor.execute("""
                    UPDATE daily_news 
                    SET sentiment_score = ?, meta_data = json_set(COALESCE(meta_data, '{}'), '$.sentiment_reason', ?)
                    WHERE id = ?
                """, (analysis['score'], analysis['reason'], item['id']))
                updated_count += 1
        else:
            logger.warning("BERT pipeline not available. Batch update skipped. Please use Agentic analysis for high-quality results.")
        
        self.db.conn.commit()
        return updated_count

